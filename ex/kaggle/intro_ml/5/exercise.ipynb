{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python and Science - https://github.com/egalli64/pysci\n",
    "\n",
    "Kaggle Courses - Intro to Machine Learning - https://www.kaggle.com/learn/intro-to-machine-learning\n",
    "\n",
    "Underfitting and Overfitting - https://www.kaggle.com/code/dansbecker/underfitting-and-overfitting\n",
    "\n",
    "melb_data.csv - https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot\n",
    "\n",
    "scikit-learn: pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See previous exercises for details\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "home_file_path = '../data/train.csv'\n",
    "home_data = pd.read_csv(home_file_path)\n",
    "\n",
    "y = home_data.SalePrice\n",
    "X = home_data[['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "home_model = DecisionTreeRegressor(random_state=1)\n",
    "home_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = home_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(f\"Validation MAE: {val_mae:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    \"\"\"Generate the MAE for the passed max leaves number on training / validation\"\"\"\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    return mean_absolute_error(val_y, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the better max leaf limit from the passed candidates\n",
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "\n",
    "maes = [(leaves, get_mae(leaves, train_X, val_X, train_y, val_y)) for leaves in candidate_max_leaf_nodes]\n",
    "print(\"Leaf cap for the minimized MAE:\", min(maes, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the found leaf limit to the full data set\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=0)\n",
    "final_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
